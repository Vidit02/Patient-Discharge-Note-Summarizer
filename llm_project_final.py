# -*- coding: utf-8 -*-
"""LLM_Project_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EBwRCZEE23e3Agfp6OzoaJinMnMRh6oi

**PIP Installs required for the project**
"""

!pip install -U datasets
!pip install fsspec
!pip install transformers datasets evaluate sentence-transformers faiss-cpu streamlit
!pip install -U transformers
!pip install rouge_score
!pip install -U huggingface_hub
!pip install -U transformers datasets evaluate rouge_score bert_score textstat

"""**Mounting Google Drive**"""

from google.colab import drive
drive.mount('/content/drive')

"""**Loading dataset from Drive**"""

import pandas as pd

file_path = '/content/drive/MyDrive/mimic-iv-bhc.csv'

df = pd.read_csv(file_path)

"""**Preprocessing the Dataset**"""

import pandas as pd
import re
import html

def preprocess_row(text: str) -> str:
    if not isinstance(text, str):
        return ""

    text = html.unescape(text)

    text = text.replace("’", "'").replace("‘", "'")\
               .replace("“", '"').replace("”", '"')\
               .replace("–", "-").replace("—", "-")

    text = re.sub(r"[^\x00-\x7F]+", " ", text)

    text = re.sub(r"\s+", " ", text).strip()

    text = text.lower()

    return text

df["input"] = df["input"].apply(preprocess_row)
df["target"] = df["target"].apply(preprocess_row)


df[["input", "target"]].sample(3).to_dict(orient="records")

"""**Splitting Data into Training and Validation**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from datasets import Dataset

df = df.dropna(subset=["input", "target"])

subset_df = df.sample(frac=0.4, random_state=42).reset_index(drop=True)

train_df, val_df = train_test_split(subset_df, test_size=0.1, random_state=42)
train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)

"""**Checking Huggingface Login**"""

from huggingface_hub import whoami

try:
    user_info = whoami()
    print("Logged in as:", user_info["name"])
except Exception as e:
    print("Not logged in or token expired:", e)

"""**Generating summaries before finetuning**"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

def generate_predictions(dataset, model_name, num_samples=10, max_input_len=512, max_output_len=128):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    preds = []
    refs = []

    samples = dataset.select(range(num_samples))

    for row in samples:
        inputs = tokenizer(row["input"], return_tensors="pt", truncation=True, padding=True, max_length=max_input_len)
        outputs = model.generate(**inputs, max_length=max_output_len, num_beams=4)
        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)
        preds.append(pred)
        refs.append(row["target"])

    return preds, refs

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from evaluate import load
import pandas as pd
import numpy as np

rouge = load("rouge")
bleu = load("bleu")
bertscore = load("bertscore")

def evaluate_all_metrics(preds, refs):
    scores = {}

    rouge_result = rouge.compute(predictions=preds, references=refs)
    scores.update(rouge_result)

    bleu_result = bleu.compute(predictions=preds, references=[[r] for r in refs])
    scores['bleu'] = bleu_result['bleu']

    bert_result = bertscore.compute(predictions=preds, references=refs, lang="en")
    scores["bertscore_precision"] = sum(bert_result["precision"]) / len(bert_result["precision"])
    scores["bertscore_recall"] = sum(bert_result["recall"]) / len(bert_result["recall"])
    scores["bertscore_f1"] = sum(bert_result["f1"]) / len(bert_result["f1"])
    return scores

t5_preds, refs = generate_predictions(val_dataset, "t5-small", num_samples=10)
bart_preds, _ = generate_predictions(val_dataset, "facebook/bart-base", num_samples=10)
pegasus_preds, _ = generate_predictions(val_dataset, "google/pegasus-pubmed", num_samples=10)

metrics = {
    "T5": evaluate_all_metrics(t5_preds, refs),
    "BART": evaluate_all_metrics(bart_preds, refs),
    "Pegasus": evaluate_all_metrics(pegasus_preds, refs)
}

import pandas as pd
import numpy as np

df_metrics = pd.DataFrame(metrics).T.round(4)
df_metrics.replace({np.nan: "N/A"}, inplace=True)
df_metrics

"""**FineTuning the 3 Models using our dataset**"""

from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    DataCollatorForSeq2Seq
)
from huggingface_hub import HfApi, login
import os

def run_training(model_name: str, hf_repo_id: str, run_name: str, train_dataset, val_dataset , isCheckpoint):
    HfApi().create_repo(
        repo_id=hf_repo_id,
        private=False,
        exist_ok=True
    )

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    def preprocess_function(examples):
        inputs = [str(x) for x in examples["input"]]
        targets = [str(x) for x in examples["target"]]
        model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding="max_length")
        labels = tokenizer(targets, max_length=128, truncation=True, padding="max_length")["input_ids"]
        model_inputs["labels"] = labels
        return model_inputs

    tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)
    tokenized_val = val_dataset.map(preprocess_function, batched=True, remove_columns=val_dataset.column_names)

    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)

    training_args = Seq2SeqTrainingArguments(
        output_dir="./results_bart",
        per_device_train_batch_size=8,
        num_train_epochs=3,
        fp16=True,
        eval_strategy="epoch",
        predict_with_generate=True,
        save_strategy="steps",
        save_steps=1000,
        save_total_limit=2,
        logging_steps=200,
        report_to="wandb",
        run_name=run_name
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_val,
        tokenizer=tokenizer,
        data_collator=data_collator
    )

    if isCheckpoint :
      trainer.train(resume_from_checkpoint=True)
    else :
      trainer.train()


    model.save_pretrained(hf_repo_id, push_to_hub=True)
    tokenizer.save_pretrained(hf_repo_id, push_to_hub=True)

    print(f"✅ Model pushed publicly to: https://huggingface.co/{hf_repo_id}")

"""**Finetuning T5-Small**"""

run_training(
    model_name="t5-small",
    hf_repo_id="Vidit202/t5-mimic-summary",
    run_name="t5-mimic-wandb",
    train_dataset=train_dataset,
    val_dataset=val_dataset
)

"""**Finetuning Bart-Base**"""

run_training(
    model_name="facebook/bart-base",
    hf_repo_id="Vidit202/bart-mimic-summary",
    run_name="bart-mimic-wandb",
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    isCheckpoint=False
)

"""**Finetuning Pegasus-Pubmed**"""

run_training(
    model_name="google/pegasus-pubmed",
    hf_repo_id="Vidit202/pegasus-pubmed-summary",
    run_name="pegasus-wandb",
    train_dataset=train_dataset,
    val_dataset=val_dataset,
    isCheckpoint=False
)

"""**Using models to generate summary**"""

import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM
)
device = "cuda" if torch.cuda.is_available() else "cpu"

model_names = {
    "t5": "Vidit202/t5-mimic-summary",
    "bart": "Vidit202/bart-mimic-summary",
    "pegasus": "Vidit202/pegasus-pubmed-summary"
}

tokenizers = {k: AutoTokenizer.from_pretrained(v) for k, v in model_names.items()}
models = {k: AutoModelForSeq2SeqLM.from_pretrained(v).to(device) for k, v in model_names.items()}

def generate_summary(model, tokenizer, text, max_input_len=512, max_output_len=128):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=max_input_len).to(device)
    outputs = model.generate(**inputs, max_length=max_output_len)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def combined_summarizer(text):
    summaries = []
    for name in ["t5", "bart", "pegasus"]:
        summary = generate_summary(models[name], tokenizers[name], text)
        summaries.append(summary)

    merged_summary_input = " ".join(summaries)

    final_summary = generate_summary(models["t5"], tokenizers["t5"], merged_summary_input)

    return {
        "T5": summaries[0],
        "BART": summaries[1],
        "Pegasus": summaries[2],
        "Combined": final_summary
    }

"""**Evaluation Metrics**"""

val_df = val_dataset.to_pandas()

results = []

for idx, row in val_df.iterrows():
    input_text = row["input"]
    reference = row["target"]

    outputs = combined_summarizer(input_text)

    results.append({
        "input": input_text,
        "reference": reference,
        "t5": outputs["T5"],
        "bart": outputs["BART"],
        "pegasus": outputs["Pegasus"],
        "combined": outputs["Combined"]
    })

    if idx >= 10:
        break

import evaluate

rouge = evaluate.load("rouge")
bleu = evaluate.load("bleu")
bertscore = evaluate.load("bertscore")

def evaluate_all_metrics(preds, refs):
    scores = {}

    rouge_result = rouge.compute(predictions=preds, references=refs)
    scores.update(rouge_result)

    bleu_result = bleu.compute(predictions=preds, references=[[r] for r in refs])
    scores['bleu'] = bleu_result['bleu']

    bert_result = bertscore.compute(predictions=preds, references=refs, lang="en")
    scores["bertscore_precision"] = sum(bert_result["precision"]) / len(bert_result["precision"])
    scores["bertscore_recall"] = sum(bert_result["recall"]) / len(bert_result["recall"])
    scores["bertscore_f1"] = sum(bert_result["f1"]) / len(bert_result["f1"])
    return scores

t5_preds = [r["t5"] for r in results]
bart_preds = [r["bart"] for r in results]
pegasus_preds = [r["pegasus"] for r in results]
combined_preds = [r["combined"] for r in results]
refs = [r["reference"] for r in results]

metrics = {
    "T5": evaluate_all_metrics(t5_preds, refs),
    "BART": evaluate_all_metrics(bart_preds, refs),
    "Pegasus": evaluate_all_metrics(pegasus_preds, refs),
    "Combined": evaluate_all_metrics(combined_preds, refs)
}

import pandas as pd
import numpy as np

df_metrics = pd.DataFrame(metrics).T.round(4)
df_metrics.replace({np.nan: "N/A"}, inplace=True)
df_metrics

"""**Custom Dataset for RAG**"""

medical_terms = {
    "hypertension": "high blood pressure",
    "hypotension": "low blood pressure",
    "myocardial infarction": "heart attack",
    "cerebrovascular accident": "stroke",
    "dyspnea": "shortness of breath",
    "analgesic": "painkiller",
    "edema": "swelling",
    "febrile": "feverish",
    "gastritis": "stomach inflammation",
    "neoplasm": "tumor",
    "hyperlipidemia": "high cholesterol",
    "renal failure": "kidney failure",
    "hematemesis": "vomiting blood",
    "hematuria": "blood in urine",
    "hematochezia": "blood in stool",
    "tachycardia": "fast heartbeat",
    "bradycardia": "slow heartbeat",
    "arrhythmia": "irregular heartbeat",
    "diaphoresis": "sweating",
    "syncope": "fainting",
    "nausea": "feeling like vomiting",
    "vomitus": "vomit",
    "anemia": "low red blood cells",
    "leukocytosis": "high white blood cells",
    "thrombocytopenia": "low platelets",
    "polyuria": "frequent urination",
    "nocturia": "urinating at night",
    "dysuria": "painful urination",
    "incontinence": "loss of bladder control",
    "hepatomegaly": "enlarged liver",
    "splenomegaly": "enlarged spleen",
    "hepatitis": "liver inflammation",
    "cirrhosis": "liver scarring",
    "osteoporosis": "weak bones",
    "osteoarthritis": "joint wear and tear",
    "rheumatoid arthritis": "joint inflammation",
    "embolism": "blood clot",
    "thrombosis": "blood clot formation",
    "ischemia": "lack of blood flow",
    "necrosis": "tissue death",
    "cyanosis": "bluish skin",
    "jaundice": "yellow skin",
    "pruritus": "itching",
    "urticaria": "hives",
    "eczema": "skin inflammation",
    "dermatitis": "skin irritation",
    "alopecia": "hair loss",
    "melena": "black stool",
    "hemoptysis": "coughing up blood",
    "pleurisy": "lung lining inflammation",
    "pneumonia": "lung infection",
    "bronchitis": "airway inflammation",
    "asthma": "narrowed airways",
    "copd": "chronic lung disease",
    "emphysema": "damaged lung sacs",
    "hypoxia": "low oxygen",
    "apnea": "not breathing",
    "dyspnea on exertion": "shortness of breath with activity",
    "orthopnea": "breathing difficulty when lying down",
    "cyanotic": "blue-colored skin",
    "tachypnea": "fast breathing",
    "bradypnea": "slow breathing",
    "sepsis": "body-wide infection",
    "bacteremia": "bacteria in the blood",
    "pyelonephritis": "kidney infection",
    "cystitis": "bladder infection",
    "nephrolithiasis": "kidney stones",
    "cholelithiasis": "gallstones",
    "cholecystitis": "gallbladder inflammation",
    "pancreatitis": "pancreas inflammation",
    "appendicitis": "appendix inflammation",
    "diverticulitis": "colon pouch inflammation",
    "gastroenteritis": "stomach flu",
    "colitis": "colon inflammation",
    "constipation": "hard stool",
    "diarrhea": "loose stool",
    "abdominal distension": "bloated belly",
    "ascites": "fluid in belly",
    "anorexia": "loss of appetite",
    "cachexia": "wasting away",
    "obesity": "excess body weight",
    "malnutrition": "poor nutrition",
    "dehydration": "lack of fluids",
    "hypoglycemia": "low blood sugar",
    "hyperglycemia": "high blood sugar",
    "diabetes mellitus": "high blood sugar condition",
    "insulin resistance": "body not responding to insulin",
    "hypothyroidism": "low thyroid activity",
    "hyperthyroidism": "overactive thyroid",
    "goiter": "swollen thyroid",
    "dysphagia": "difficulty swallowing",
    "dysphasia": "difficulty speaking",
    "aphasia": "loss of ability to speak",
    "ataxia": "loss of coordination",
    "paresthesia": "tingling or numbness",
    "paralysis": "loss of movement",
    "spasticity": "stiff muscles",
    "seizure": "uncontrolled brain activity",
    "epilepsy": "recurring seizures",
    "headache": "head pain",
    "migraine": "intense headache",
    "encephalopathy": "brain dysfunction",
    "meningitis": "brain lining infection",
    "delirium": "confused thinking",
    "dementia": "memory loss",
    "psychosis": "loss of reality",
    "mania": "extreme mood elevation",
    "depression": "persistent sadness",
    "anxiety": "excessive worry",
    "hallucination": "seeing or hearing things",
    "delusion": "false belief",
    "bipolar disorder": "mood swings",
    "schizophrenia": "chronic mental illness",
    "ptsd": "trauma-related stress",
    "ocd": "repetitive thoughts or actions",
    "insomnia": "difficulty sleeping",
    "narcolepsy": "excessive daytime sleepiness",
    "apnea": "stopping breathing",
    "arrhythmia": "irregular heart rhythm",
    "valvular disease": "heart valve problem",
    "congestive heart failure": "heart pumping problem",
    "cardiomyopathy": "heart muscle disease",
    "pericarditis": "heart lining inflammation",
    "angina": "chest pain",
    "aortic aneurysm": "bulge in the aorta",
    "deep vein thrombosis": "blood clot in leg vein",
    "pulmonary embolism": "clot in lung artery",
    "shock": "dangerously low blood pressure",
    "anaphylaxis": "severe allergic reaction",
    "urticaria": "hives",
    "eczema": "skin inflammation",
    "psoriasis": "scaly skin",
    "seborrheic dermatitis": "flaky scalp",
    "keratosis": "skin bump",
    "melanoma": "skin cancer",
    "basal cell carcinoma": "skin cancer",
    "squamous cell carcinoma": "skin cancer",
    "biopsy": "tissue sample",
    "pathology": "study of disease",
    "benign": "not cancerous",
    "malignant": "cancerous",
    "metastasis": "spread of cancer",
    "oncology": "cancer care",
    "radiotherapy": "radiation treatment",
    "chemotherapy": "cancer drug treatment",
    "immunotherapy": "immune-based treatment",
    "lymphadenopathy": "swollen lymph nodes",
    "tonsillitis": "tonsil infection",
    "sinusitis": "sinus infection",
    "otitis media": "ear infection",
    "conjunctivitis": "pink eye",
    "pharyngitis": "sore throat",
    "laryngitis": "voice box inflammation",
    "bronchiolitis": "small airway inflammation",
    "pneumothorax": "collapsed lung",
    "pleural effusion": "fluid around lungs",
    "atelectasis": "lung collapse",
    "intubation": "inserting breathing tube",
    "extubation": "removing breathing tube",
    "tracheostomy": "neck breathing tube",
    "ventilator": "breathing machine",
    "resuscitation": "reviving from death",
    "cardiac arrest": "heart stops",
    "do not resuscitate": "no revival order",
    "code blue": "medical emergency",
    "advance directive": "care instructions in advance",
    "palliative care": "comfort care",
    "hospice": "end-of-life care",
    "autopsy": "after-death exam",
    "morbidity": "illness",
    "mortality": "death",
    "prognosis": "expected outcome",
    "diagnosis": "identified condition",
    "treatment": "care plan",
    "prescription": "medicine order",
    "dosage": "medicine amount",
    "contraindication": "reason not to use",
    "adverse reaction": "bad effect",
    "side effect": "unintended effect",
    "tolerance": "resistance to drug",
    "dependence": "reliance on drug",
    "withdrawal": "symptoms after stopping",
    "overdose": "too much medicine",
    "toxicity": "poison effect",
    "placebo": "fake treatment",
    "clinical trial": "research study",
    "vital signs": "body measurements",
    "temperature": "body heat",
    "pulse": "heartbeat rate",
    "respiration": "breathing rate",
    "blood pressure": "pressure in arteries"
}

"""**RAG Code Implementaion**"""

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

retriever_model = SentenceTransformer("all-MiniLM-L6-v2")

jargon_terms = list(medical_terms.keys())
layman_terms = list(medical_terms.values())

jargon_embeddings = retriever_model.encode(jargon_terms, convert_to_numpy=True)
index = faiss.IndexFlatL2(jargon_embeddings.shape[1])
index.add(jargon_embeddings)

def simplify_summary(summary, top_k=1):
    words = summary.split()
    simplified = []

    for word in words:
        cleaned = word.strip(",.?!:;()").lower()
        if cleaned in medical_terms:
            simplified.append(medical_terms[cleaned])
            continue

        embedding = retriever_model.encode([cleaned], convert_to_numpy=True)
        D, I = index.search(embedding, top_k)

        if D[0][0] < 0.7:
            simplified.append(layman_terms[I[0][0]])
        else:
            simplified.append(word)

    return " ".join(simplified)

for result in results[:5]:
    print("Original Summary:\n", result["combined"])
    simplified = simplify_summary(result["combined"])
    print("\nSimplified Summary:\n", simplified)
    print("=" * 60)

"""**Example after implementing RAG**"""

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model = AutoModelForSeq2SeqLM.from_pretrained("Vidit202/bart-mimic-summary")
tokenizer = AutoTokenizer.from_pretrained("Vidit202/bart-mimic-summary")
discharge_note = """Ms. ___ was admitted to the bariatric service with
abdominal pain after being transferred from an OSH with a CT
read of possible small bowel obstruction. Due to her ___ en y
gastric bypass, there was concern of an internal hernia and need
for operative intervention. On arrival, she had a nutritional
IV fluids given ("banana bag") which consisted of thiamine and
Vitamin B12. Stat CBC/chem10 and lactate revealed no etiology
of her abdominal pain. She had normal LFTs, lipase, lactate,
and white count. She was started on an IV BID PPI and IVF and
made NPO. She had a repeat CT abdomen with PO contrast to
better evaluate for a small bowel obstruction. There were no
abnormal findings on the CT scan. Her diet was advanced to
stage III which she tolerated well. Nutrition labs were drawn
which revealed iron deficiency. On questioning, she reported
not following up with a nutritionist and not being aware of
having her vitamin levels drawn by her PCP since her ___ en Y
gastric bypass. The importance of having close nutritional
follow up due to her altered anatomy was emphasized, including
following closely Vitamin B1, B12, iron, vitamin D, and folate.
Her primary care physician ___ was also telephoned and
a message was with left with his office to communicate these
recommendations. She had also been taking NSAIDs in the past
and was unaware of their danger with after a gastric bypass, and
the need to avoid NSAIDs was also reinforced.

On the day of discharge, she was tolerating a stage III
bariatric diet. Her pain was well controlled. She was voiding
freely. She was ambulating independently without assistance.
She will follow up with her PCP in one to two weeks."""

input_only = f"Discharge Summary:\n{discharge_note}\n\nPlease simplify this discharge summary."
inputs = tokenizer(input_only, return_tensors="pt").to(model.device)
output = model.generate(**inputs, max_new_tokens=128)
summary_without_rag = tokenizer.decode(output[0], skip_special_tokens=True))